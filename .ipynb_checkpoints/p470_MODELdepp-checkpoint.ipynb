{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3e9db28-325a-4e08-8445-e7a05f635e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_excel(\"Email_Marketing_Campaign_Dataset_Rounded.xlsx\")\n",
    "\n",
    "numerical_columns=data.select_dtypes(include=['number']).columns\n",
    "\n",
    "\n",
    "# outlier detection\n",
    "def outlier_detection(df,colname): #creating function to finding outiers in each columns\n",
    "    #calculate the Q1,Q3 and IQR\n",
    "    q1=df[colname].quantile(0.25)\n",
    "    q3=df[colname].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "\n",
    "    upper_extreme=q3+(1.5 * iqr)\n",
    "    lower_extreme=q1-(1.5 * iqr)\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = df[(df[colname] < lower_extreme) | (df[colname] > upper_extreme)]\n",
    "\n",
    "\n",
    "    return lower_extreme,upper_extreme,q1,q3,outliers\n",
    "\n",
    "#handling outliers by capping them\n",
    "def handle_outliers(df,column):\n",
    "    lower_extreme, upper_extreme,_,_,_=outlier_detection(data,column)\n",
    "    df[column]=df[column].clip(lower=lower_extreme,upper=upper_extreme)\n",
    "    #Any value less than the lower_extreme will be replaced by lower_extreme.\n",
    "    #Any value greater than the upper_extreme will be replaced by upper_extreme.\n",
    "    return df\n",
    "    \n",
    "for column in numerical_columns:\n",
    "    data=handle_outliers(data,column)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_data=data.copy() #creating a copy of the original data to ensure that any transformations do not affect the original dataset. \n",
    "\n",
    "\n",
    "##advanced preprocessing \n",
    "\n",
    "#age binning (bins the Customer_Age column into four age groups: Teen, Young Adult, Middle Aged, and Senior.)\n",
    "bins=[0,18,35,50,100]\n",
    "labels=['teen', 'young_adult', 'middle_aged', 'senior ']\n",
    "#Ages 0–18 fall into \"Teen.\"\n",
    "#Ages 19–35 fall into Young Adult\n",
    "#Ages 36–50 fall into Middle Aged\n",
    "#Ages 51–100 fall into Senior\n",
    "model_data['Age_group']=pd.cut(data['Customer_Age'],bins=bins,labels=labels)\n",
    "\n",
    "\n",
    "#remove the col customer age as we have created age groups col\n",
    "model_data=model_data.drop(columns=['Customer_Age'])\n",
    "\n",
    "\n",
    "#encode the age_group col\n",
    "\n",
    "#apply label encoding\n",
    "label_encoder=LabelEncoder()\n",
    "model_data['Age_group']=label_encoder.fit_transform(model_data['Age_group'])\n",
    "\n",
    "\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "\n",
    "\n",
    "#split the data in to features(x) and target(y=opened_previous_emails)\n",
    "x=model_data.drop(columns=['Opened_Previous_Emails']) # all cols except target variable\n",
    "y=model_data['Opened_Previous_Emails'] #target variable\n",
    "\n",
    "\n",
    "#standardization (only numerical coloumn not the binary ones)\n",
    "#(seperating binary columns and numerical coloumns)\n",
    "binary_columns=['Opened_Previous_Emails','Clicked_Previous_Emails','Device_Type','Age_group']\n",
    "#seperate numerical cols to standardize\n",
    "numerical_columns=[col for col in x.columns if col not in binary_columns]\n",
    "\n",
    "\n",
    "# Apply StandardScaler to numerical columns only (exclude binary columns)\n",
    "scaler = StandardScaler()\n",
    "x[numerical_columns]=scaler.fit_transform(x[numerical_columns])\n",
    "x #standized features table\n",
    "\n",
    "\n",
    "x_bootstrapped,y_bootstrapped=resample(x,y,replace=True,n_samples=len(x)*2,random_state=42)\n",
    "\n",
    "#split the data into training and testing data\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_bootstrapped,y_bootstrapped,test_size=0.3,random_state=42)\n",
    "\n",
    "#Random Forest Implementation: (with hyper parameter tuning)\n",
    "\n",
    "\n",
    "\n",
    "# Best parameters obtained from hyperparameter tuning\n",
    "best_params = { 'n_estimators': 369, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False }\n",
    "\n",
    "#initilaize and train the random forest model\n",
    "rf_model=RandomForestClassifier(**best_params,random_state=42)\n",
    "\n",
    "\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_rf = rf_model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "filename = 'trained_rf_model.sav'\n",
    "\n",
    "pickle.dump(rf_model, open(filename, 'wb'))\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = pickle.load(open('trained_rf_model.sav', 'rb'))\n",
    "\n",
    "def process_age(age):\n",
    "    \"\"\"\n",
    "    Process raw age input to match the trained model's expectations.\n",
    "    Args:\n",
    "        age (int): Raw age input from the user.\n",
    "    Returns:\n",
    "        int: Encoded age group.\n",
    "    \"\"\"\n",
    "    # Define bins and labels\n",
    "    age_bins = [0, 18, 35, 50, 100]\n",
    "    age_labels = ['teen', 'young_adult', 'middle_aged', 'senior']\n",
    "    \n",
    "    # Bin the age\n",
    "    age_group = pd.cut([age], bins=age_bins, labels=age_labels)[0]\n",
    "    \n",
    "    # Encode the age group\n",
    "    age_group_encoded = label_encoder.transform([age_group])[0]\n",
    "    \n",
    "    return age_group_encoded\n",
    "\n",
    "\n",
    "def preprocess_input(age, emails_opened, emails_clicked, purchase_history, \n",
    "                     time_spent, days_since_last_open, engagement_score, \n",
    "                     device_type, clicked_previous_emails):\n",
    "    \"\"\"\n",
    "    Preprocess raw inputs for prediction.\n",
    "    Args:\n",
    "        age (int): Customer's raw age.\n",
    "        emails_opened (int): Number of emails opened by the customer.\n",
    "        emails_clicked (int): Number of emails clicked by the customer.\n",
    "        purchase_history (float): Total amount spent by the customer.\n",
    "        time_spent (float): Time spent on the website in minutes.\n",
    "        days_since_last_open (int): Days since the last email was opened.\n",
    "        engagement_score (float): Customer engagement score.\n",
    "        device_type (int): Device type (0 for Desktop, 1 for Mobile).\n",
    "        clicked_previous_emails (int): Binary value indicating if previous emails were clicked (0 or 1).\n",
    "    Returns:\n",
    "        np.array: Preprocessed input ready for prediction.\n",
    "    \"\"\"\n",
    "    # Step 1: Process age into encoded age group\n",
    "    age_group_encoded = process_age(age)\n",
    "    \n",
    "    # Step 2: Standardize numerical features\n",
    "    numerical_data = scaler.transform([[emails_opened, emails_clicked, purchase_history,\n",
    "                                        time_spent, days_since_last_open, engagement_score]])\n",
    "    \n",
    "    # Step 3: Combine all features into a single input array\n",
    "    final_input = np.hstack([\n",
    "        [device_type],             # Device type (binary)\n",
    "        [clicked_previous_emails], # Clicked Previous Emails (binary)\n",
    "        [age_group_encoded],       # Encoded age group\n",
    "        numerical_data[0]          # Standardized numerical features\n",
    "    ])\n",
    "    \n",
    "    return final_input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978b13b1-2f9d-4b45-b0e4-4dd0e55321ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amarm\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example test input\n",
    "test_input = x_test.iloc[0].values.reshape(1, -1)  # First test sample\n",
    "prediction = loaded_model.predict(test_input)\n",
    "\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7c041-aa2f-436b-a93b-52f2feb9d692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
